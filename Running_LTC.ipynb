{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuracion de grafica a usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    " \n",
    "# lA ID de la GPU a usar, puede ser desde 0 hasta las N GPU's. Si es -1 significa que es en la CPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importacion de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from IPython.display import display, clear_output\n",
    "from ipywidgets import interact, IntSlider\n",
    "import h5py\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from LTC import *\n",
    "!wget -q https://raw.githubusercontent.com/JefeLitman/VideoDataGenerator/master/DatasetsLoaderUtils.py -O DatasetsLoaderUtils.py\n",
    "from DatasetsLoaderUtils import load_videoFrames_from_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuraciones para Tensorflow y Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(8128)\n",
    "np.random.seed(8128)\n",
    "tf.random.set_seed(8128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/home/jefelitman/DataSets/ucf101/split_1\"\n",
    "root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 20\n",
    "batch_size = 30\n",
    "size = [112, 112]\n",
    "frames = 16\n",
    "canales = 3\n",
    "video_shape = tuple([frames]+size[::-1]+[canales])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version antiguo con VideoDataGenerator"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def custom_steps_temporal(frames):\n",
    "    paso = len(frames)//60\n",
    "    videos = []\n",
    "    for i in range(paso):\n",
    "        indices = range(i, len(frames),paso)\n",
    "        videos.append([frames[j] for j in indices[:60]])\n",
    "    return videos"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def custom_temp_crop_unique(frames):\n",
    "    mitad = len(frames)//2\n",
    "    paso = len(frames)//60\n",
    "    indices = sorted(list(range(mitad, -1,-paso)) + list(range(mitad+paso, len(frames),paso)))\n",
    "    indices = indices[len(indices)//2 - 30 : len(indices)//2 + 30]\n",
    "    return [[frames[i] for i in indices]]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def half_video_temporal(frames):\n",
    "    mitad = len(frames)//2\n",
    "    return [frames[mitad-8*2:mitad+8*2]]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def video_transf(video):\n",
    "    escalador = MinMaxScaler()\n",
    "    new_video = video.reshape((video.shape[0]*video.shape[1]*video.shape[2]*video.shape[3],1))\n",
    "    new_video = escalador.fit_transform(new_video)\n",
    "    return new_video.reshape((video.shape[0],video.shape[1],video.shape[2],video.shape[3]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def video_scaled(video):\n",
    "    return video/255."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def flip_vertical(volume):\n",
    "    return np.flip(volume, (0, 2))[::-1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def corner_frame_crop(original_width, original_height):\n",
    "    x = original_width-112\n",
    "    y = original_height-112\n",
    "    return [[x//2, original_width - x//2 -1, y//2, original_height-y//2],\n",
    "            [x//2, original_width - x//2 -1, y//2, original_height-y//2]\n",
    "           ]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataset = VideoDataGenerator(directory_path = root_path, \n",
    "                             table_paths = None, \n",
    "                             batch_size = batch_size, \n",
    "                             original_frame_size = original_size, \n",
    "                             frame_size=size, \n",
    "                             video_frames = frames, \n",
    "                             temporal_crop = (\"custom\", custom_steps_temporal),\n",
    "                             video_transformation = [(\"augmented\",flip_vertical),(\"full\",video_scaled)],\n",
    "                             frame_crop = (None, None), \n",
    "                             shuffle = True,\n",
    "                             shuffle_after_epoch = True,\n",
    "                             conserve_original = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version nueva con load_videoFrames"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def time_sampling(video):\n",
    "    if len(video) < 60:\n",
    "        new_video = np.concatenate([video, np.zeros([60 - len(video), 58, 58, 3])], axis=0)\n",
    "    else:\n",
    "        new_video = video\n",
    "    mitad = len(new_video)//2\n",
    "    return new_video[mitad-30:mitad+30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_videoFrames_from_path(root_path, lambda x: x, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = dataset.data_generator(1, canales)\n",
    "test_gen = dataset.data_generator(2, canales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gen_sampling():\n",
    "    for v, l in train_gen:\n",
    "        paso = len(v)//16\n",
    "        if paso == 0:\n",
    "            video = np.concatenate([v, np.zeros([16 - len(v), 112, 112, 3])], axis=0)\n",
    "        else:\n",
    "            video = v\n",
    "        for j in range(paso):\n",
    "            yield video[j::paso][:16], l\n",
    "def test_gen_sampling():\n",
    "    for v, l in test_gen:\n",
    "        paso = len(v)//16\n",
    "        if paso == 0:\n",
    "            video = np.concatenate([v, np.zeros([16 - len(v), 112, 112, 3])], axis=0)\n",
    "        else:\n",
    "            video = v\n",
    "        for j in range(paso):\n",
    "            yield video[j::paso][:16], l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "107039/30 # Cantidad de batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(video, label):\n",
    "    return video/255., label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_flip_horizontal(video, label):\n",
    "    return tf.reverse(video, [2]), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"cache\")\n",
    "# Train dataset\n",
    "train_data = tf.data.Dataset.from_generator(train_gen_sampling, (tf.float32, tf.int64), \n",
    "                                            (video_shape, []))\n",
    "train_data = train_data.cache('cache/train').map(scale, 24)\n",
    "#train_data = train_data.concatenate(train_data.map(video_flip_horizontal, 24))\n",
    "\n",
    "#  Test dataset\n",
    "test_data = tf.data.Dataset.from_generator(test_gen_sampling, (tf.float32, tf.int64), \n",
    "                                            (video_shape, []))\n",
    "test_data = test_data.cache(\"cache/test\").map(scale, 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Neuronal LTC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construccion del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrada de la red neuronal\n",
    "dropout = 0.5\n",
    "lr = 1e-3\n",
    "weigh_decay = 5e-3\n",
    "\n",
    "ltc_save_path = '/home/jefelitman/Saved_Models/trained_ucf/No_Encoder/no_inception/LTC-ori_split1_{w}x{h}x{f}_SGD_'.format(\n",
    "        w=size[0], h=size[1],f=frames)\n",
    "if canales == 3:\n",
    "    ltc_save_path += 'RGB_'\n",
    "else:\n",
    "    ltc_save_path += 'B&N_'\n",
    "\n",
    "ltc_save_path += 'lr={l}_DO_IC_TDM_S255_VFH_E{e}'.format(l = lr, e = epoch)\n",
    "\n",
    "#Creacion de la carpeta donde se salvara el modelo\n",
    "if not os.path.isdir(ltc_save_path):\n",
    "    os.mkdir(ltc_save_path)\n",
    "model_saves_path = os.path.join(ltc_save_path,'model_saves')\n",
    "if not os.path.isdir(model_saves_path):\n",
    "    os.mkdir(model_saves_path)\n",
    "ltc_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parametros para la compilacion del modelo\n",
    "optimizador = keras.optimizers.SGD(learning_rate=lr, momentum=0.9)\n",
    "#optimizador = keras.optimizers.Adam(learning_rate=lr)\n",
    "perdida = keras.losses.SparseCategoricalCrossentropy(name=\"loss\")\n",
    "precision = keras.metrics.SparseCategoricalAccuracy(name=\"acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltc = get_LTC_original(video_shape, len(dataset.to_class), dropout, weigh_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compilacion del modelo\n",
    "ltc.compile(optimizer = optimizador,\n",
    "           loss = perdida,\n",
    "           metrics = [precision])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.utils.plot_model(ltc, 'LTC.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ltc = keras.models.load_model(os.path.join(ltc_save_path,'ltc_final_1000.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargo los pesos pre entrenados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pesos del C3D"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "c3d_weights = h5py.File('/home/jefelitman/Saved_Models/c3d-sports1M_weights.h5', 'r')\n",
    "print(c3d_weights.keys())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "c3d_weights['layer_0'].keys()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "weights = []\n",
    "for capa in ['layer_0','layer_2','layer_4','layer_5','layer_5']:\n",
    "    weights.append([\n",
    "        np.moveaxis(np.r_[c3d_weights[capa]['param_0']], (0,1),(4,3)), #Cambio los ejes porque c3d estan con canales primero\n",
    "        np.r_[c3d_weights[capa]['param_1']]\n",
    "                   ])\n",
    "for index, capa in enumerate(['conv3d_1','conv3d_2','conv3d_3','conv3d_4','conv3d_5']):\n",
    "    ltc.get_layer(capa).set_weights(weights[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pesos de la InceptionV3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "inceptionv3 = keras.applications.InceptionV3(weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for layer, index in [('conv3d_1',1),('conv3d_2',4),('conv3d_3',7),('conv3d_4',11),('conv3d_5',14)]:\n",
    "    old_weights, old_bias = ltc.get_layer(layer).get_weights()\n",
    "    new_weight = np.zeros(old_weights.shape)\n",
    "    new_bias = np.zeros(old_bias.shape)\n",
    "    pesos = inceptionv3.layers[index].get_weights()[0]\n",
    "    for entrada in range(old_weights.shape[3]):\n",
    "        for salida in range(old_weights.shape[4]):\n",
    "            new_weight[:,:,:,entrada,salida] = np.stack([pesos[:,:,entrada%pesos.shape[2],salida%pesos.shape[3]], \n",
    "                                                         pesos[:,:,entrada%pesos.shape[2],salida%pesos.shape[3]], \n",
    "                                                         pesos[:,:,entrada%pesos.shape[2],salida%pesos.shape[3]]\n",
    "                                                        ]\n",
    "                                                       )/3\n",
    "    ltc.get_layer(layer).set_weights([new_weight, new_bias])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de la red con el generador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion customizadas para el entrenamiento del modelo \n",
    "def cambio_lr(epoch, lr):\n",
    "    if epoch == 10 or epoch == 16 :\n",
    "        for i in ['conv3d_1','conv3d_2','conv3d_3','conv3d_4', 'conv3d_5','dense_6','dense_7','dense_8']:\n",
    "            weigh_decay = ltc.get_layer(i).kernel_regularizer.get_config()['l2'] * 0.1\n",
    "            ltc.get_layer(i).kernel_regularizer = keras.regularizers.l2(weigh_decay)\n",
    "        return optimizador.learning_rate.numpy() * 0.1\n",
    "    else:\n",
    "        return optimizador.learning_rate.numpy()\n",
    "\n",
    "funciones = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(model_saves_path,'ltc_epoch_{epoch}.h5'),\n",
    "        save_best_only=True,\n",
    "        monitor='val_acc',\n",
    "        verbose=1),\n",
    "    keras.callbacks.LearningRateScheduler(cambio_lr, verbose=1),\n",
    "    keras.callbacks.CSVLogger(os.path.join(ltc_save_path,'output.csv'))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_data = train_data.shuffle(len(dataset.__videos_train_path__),\n",
    "                                reshuffle_each_iteration=True).batch(batch_size).prefetch(1)\n",
    "\n",
    "test_data = test_data.shuffle(len(dataset.__videos_test_path__),\n",
    "                              reshuffle_each_iteration=True).batch(batch_size).prefetch(1)\n",
    "\n",
    "historial = ltc.fit(x = train_data,\n",
    "                 epochs=epoch,\n",
    "                 callbacks=funciones,\n",
    "                 validation_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardado del modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salvado final definitivo del modelo una vez se detenga\n",
    "ltc.save(os.path.join(ltc_save_path,\"ltc_final_{e}.h5\".format(e=epoch)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficas de los resultados de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(historial.history[\"loss\"],'k--')\n",
    "plt.plot(historial.history[\"val_loss\"],'b--')\n",
    "plt.title('Loss over epochs')\n",
    "plt.legend(labels=[\"Loss\",\"Val_Loss\"])\n",
    "plt.show()\n",
    "fig.savefig(os.path.join(ltc_save_path,'train_loss_epochs_{e}.png'.format(e=epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(historial.history[\"acc\"],'k--')\n",
    "plt.plot(historial.history[\"val_acc\"],'b--')\n",
    "plt.title('Accuracy over epochs')\n",
    "plt.legend(labels=[\"Accuracy\",\"Val_Accuracy\"])\n",
    "plt.show()\n",
    "fig.savefig(os.path.join(ltc_save_path,'train_accuracy_epochs_{e}.png'.format(e=epoch)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluacion del entrenamiento"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "resultados = ltc.evaluate_generator(generator=dataset.get_test_generator(canales),\n",
    "                      steps=dataset.test_batches,\n",
    "                      max_queue_size=batch_size)\n",
    "print(\"\"\"Los resultados de la evaluacion del modelo fueron: \n",
    "Perdida: {l}\n",
    "Precision: {a}\"\"\".format(l=resultados[0],a=resultados[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
